import re
from src.core.llm_engine import engine
from src.config.prompts import STATE_JUDGE_PROMPT

def clean_output(text):
    """æ¸…æ´— <think> æ ‡ç­¾ï¼Œåªä¿ç•™æœ€ç»ˆç»“è®º"""
    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)
    text = text.replace('**', '').replace('ã€', '').replace('ã€‘', '')
    return text.strip()

def state_judge_node(state: dict):
    """
    ã€çŠ¶æ€åˆ¤æ–­æ¨¡å— - é€šç”¨ç‰ˆã€‘
    åŠ¨æ€è¯»å–è§’è‰²é…ç½®ä¸­çš„ valid_states è¿›è¡Œåˆ¤æ–­
    """
    query = state["user_query"]
    history = state.get("chat_history", [])[-3:]
    
    # --- æ ¸å¿ƒä¿®æ”¹ï¼šä» State ä¸­è·å–é…ç½® ---
    config = state.get("char_config", {})
    name = config.get("name", "Agent")
    
    # è·å–å¯é€‰çŠ¶æ€åˆ—è¡¨ï¼Œå¦‚æœ JSON é‡Œæ²¡å†™ï¼Œç»™ä¸ªé»˜è®¤å€¼é˜²æ­¢æŠ¥é”™
    valid_states = config.get("valid_states", ["å¹³é™", "å¼€å¿ƒ", "ç”Ÿæ°”"])
    valid_states_str = ", ".join(valid_states)
    # ----------------------------------
    
    # æ³¨å…¥å˜é‡åˆ°æ¨¡æ¿
    prompt = STATE_JUDGE_PROMPT.format(
        name=name,
        valid_states=valid_states_str,
        query=query, 
        history=history
    )
    
    raw_response = engine.generate(prompt, max_tokens=1024, temperature=0.1)
    mood = clean_output(raw_response)
    
    if mood:
        print(f"ğŸ§  [State Judge] æ£€æµ‹åˆ°æƒ…ç»ª: {mood}")
        return {"current_mood": mood}
    else:
        print(f"âš ï¸ [State Judge] è§£æå¤±è´¥ï¼ŒåŸå§‹è¾“å‡º: {raw_response[:50]}...")
        # å…œåº•è¿”å›åˆ—è¡¨é‡Œçš„ç¬¬ä¸€ä¸ªçŠ¶æ€
        return {"current_mood": valid_states[0] if valid_states else "å¹³é™"}